import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
import joblib
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier
from sklearn.ensemble import RandomForestClassifier

# ëª¨ë¸ íŒŒì¼ ë° íŒŒë¼ë¯¸í„° íŒŒì¼ì„ ì €ì¥í•  í´ë” ìƒì„±
MODEL_PATH = "open/models"
os.makedirs(MODEL_PATH, exist_ok=True)

def load_and_preprocess_data():
    """
    train.csvì™€ test.csvë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ ìˆ˜í–‰.
    - train.csv: í•™ìŠµ ë°ì´í„°ì™€ íƒ€ê²Ÿ ë¶„ë¦¬ (ë§Œì•½ "ID" ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì œê±°)
    - test.csv: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë° ID ë¶„ë¦¬ (ID ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©)
    - ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê²°ì¸¡ì¹˜ëŠ” "missing"ìœ¼ë¡œ ì±„ìš°ê³  Label Encoding ì ìš©
    """
    print("\n=== ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì‹œì‘ ===")
    try:
        train = pd.read_csv("train.csv")
        test = pd.read_csv("test.csv")
        print("âœ“ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None, None, None, None

    # train ë°ì´í„°ì— 'ID' ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì œê±°í•©ë‹ˆë‹¤.
    if "ID" in train.columns:
        train = train.drop(columns=["ID"])
    
    # í•™ìŠµ ë°ì´í„°ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
    X = train.drop(columns=["ì„ì‹  ì„±ê³µ ì—¬ë¶€"])
    y = train["ì„ì‹  ì„±ê³µ ì—¬ë¶€"]
    
    # test ë°ì´í„°ì—ì„œ 'ID' ì»¬ëŸ¼ì€ ì¶”í›„ ì œì¶œìš©ìœ¼ë¡œ ë¶„ë¦¬
    if "ID" in test.columns:
        test_ids = test["ID"].values
        X_test = test.drop(columns=["ID"])
    else:
        print("â„¹ï¸ test.csvì— 'ID' ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        test_ids = np.arange(len(test))
        X_test = test.copy()

    # ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬: ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° ë° Label Encoding ì ìš©
    from sklearn.preprocessing import LabelEncoder
    cat_features = X.select_dtypes(include=['object']).columns.tolist()
    for col in cat_features:
        X[col] = X[col].fillna("missing")
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col])
    cat_features_test = X_test.select_dtypes(include=['object']).columns.tolist()
    for col in cat_features_test:
        X_test[col] = X_test[col].fillna("missing")
        le = LabelEncoder()
        X_test[col] = le.fit_transform(X_test[col])
    
    print(f"âœ“ í•™ìŠµ ë°ì´í„° shape: {X.shape}")
    print(f"âœ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° shape: {X_test.shape}")
    
    return X, X_test, y, test_ids

def load_best_params():
    """
    ì €ì¥ëœ ê° ëª¨ë¸ì˜ ìµœì  íŒŒë¼ë¯¸í„° íŒŒì¼ì—ì„œ íŒŒë¼ë¯¸í„°ë¥¼ ë¶ˆëŸ¬ì˜´.
    ë§Œì•½ íŒŒì¼ì— "params" í‚¤ê°€ ìˆë‹¤ë©´ í•´ë‹¹ ê°’ì„, ì—†ë‹¤ë©´ ë¡œë“œí•œ dict ìì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    print("\n=== ìµœì  íŒŒë¼ë¯¸í„° ë¡œë“œ ===")
    try:
        best_params = {}

        # XGBoost
        xgb_params = joblib.load('open/best_xgb_params.pkl')
        best_params["xgb"] = xgb_params["params"] if isinstance(xgb_params, dict) and "params" in xgb_params else xgb_params

        # LightGBM
        try:
            lgb_params = joblib.load('open/best_lgbm_params.pkl')
        except Exception:
            lgb_params = joblib.load('open/best_lightgbm_params.pkl')
        best_params["lgb"] = lgb_params["params"] if isinstance(lgb_params, dict) and "params" in lgb_params else lgb_params

        # CatBoost
        cat_params = joblib.load('open/best_catboost_params.pkl')
        best_params["cat"] = cat_params["params"] if isinstance(cat_params, dict) and "params" in cat_params else cat_params

        # RandomForest
        rf_params = joblib.load('open/best_rf_params.pkl')
        best_params["rf"] = rf_params["params"] if isinstance(rf_params, dict) and "params" in rf_params else rf_params

        print("âœ“ ëª¨ë“  ëª¨ë¸ì˜ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return best_params
    except Exception as e:
        print(f"âŒ íŒŒë¼ë¯¸í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None

def load_or_train_models(X_train, y_train, params, force_retrain=False):
    """
    ì €ì¥ëœ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì´ìš©í•´ ëª¨ë¸ ê°ì²´ë¥¼ ìƒì„±í•œ í›„,
    open/models í´ë”ì— ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œí•˜ê³ ,
    ì—†ìœ¼ë©´ í•™ìŠµì‹œì¼œ ì €ì¥í•œë‹¤.
    """
    print("\n=== ëª¨ë¸ ë¡œë“œ ë˜ëŠ” í•™ìŠµ ì‹œì‘ ===")
    models = {
        "xgboost": xgb.XGBClassifier(**params["xgb"], use_label_encoder=False, eval_metric="auc"),
        "lightgbm": lgb.LGBMClassifier(**params["lgb"]),
        "catboost": CatBoostClassifier(**params["cat"], verbose=False, eval_metric="AUC"),
        "randomforest": RandomForestClassifier(**params["rf"], random_state=42, n_jobs=-1)
    }
    
    for name, model in models.items():
        model_path = f"{MODEL_PATH}/{name}_model.pkl"
        if os.path.exists(model_path) and not force_retrain:
            print(f"âœ“ {name} ëª¨ë¸ ë¡œë“œ ì¤‘...")
            models[name] = joblib.load(model_path)
        else:
            print(f"âš™ï¸ {name} ëª¨ë¸ í•™ìŠµ ì¤‘...")
            model.fit(X_train, y_train)
            joblib.dump(model, model_path)
            print(f"âœ“ {name} ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ")
    
    return models

def evaluate_model(model, X_val, y_val):
    """
    ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê²€ì¦ ë°ì´í„°(X_val)ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  ROC-AUC ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ë°˜í™˜.
    """
    y_pred = model.predict_proba(X_val)[:, 1]
    score = roc_auc_score(y_val, y_pred)
    return score, y_pred

def main():
    print("\nğŸš€ ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ ì‹¤í–‰")
    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    X, X_test, y, test_ids = load_and_preprocess_data()
    if X is None:
        return
    # í•™ìŠµ ë°ì´í„°ë¥¼ 80:20 ë¹„ìœ¨ë¡œ ë‚˜ëˆ„ì–´ ê²€ì¦ ë°ì´í„° ë¶„ë¦¬
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    # ì €ì¥ëœ ìµœì  íŒŒë¼ë¯¸í„° ë¶ˆëŸ¬ì˜¤ê¸°
    params = load_best_params()
    if params is None:
        return
    
    # ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë¡œë“œ ë˜ëŠ” í•™ìŠµ
    models = load_or_train_models(X_train, y_train, params, force_retrain=False)
    
    # ê° ëª¨ë¸ì˜ ê²€ì¦ ROC-AUC í‰ê°€ ë° ì¶œë ¥
    scores = {}
    for name, model in models.items():
        score, _ = evaluate_model(model, X_val, y_val)
        scores[name] = score
        print(f"{name} ëª¨ë¸ì˜ ê²€ì¦ ROC-AUC: {score:.4f}")
    
    # ê° ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ test.csvì— ëŒ€í•´ ì˜ˆì¸¡ ìˆ˜í–‰ ë° ê°œë³„ CSV íŒŒì¼ ì €ì¥
    for name, model in models.items():
        print(f"{name} ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
        pred = model.predict_proba(X_test)[:, 1]
        submission = pd.DataFrame({
            "ID": test_ids,
            "probability": pred
        })
        output_path = f"submission_{name}.csv"
        submission.to_csv(output_path, index=False)
        print(f"âœ¨ {name} ì˜ˆì¸¡ ì™„ë£Œ! {output_path} íŒŒì¼ ìƒì„±ë¨")
    
    # ê²€ì¦ ROC-AUC ìš”ì•½ ì¶œë ¥
    print("\n=== ê°œë³„ ëª¨ë¸ ê²€ì¦ ROC-AUC ìš”ì•½ ===")
    for name, score in scores.items():
        print(f"{name}: {score:.4f}")

if __name__ == "__main__":
    main()

print(">> [model_prediction_efficient] íŒŒì¼ ì‹¤í–‰ ì¢…ë£Œ")
