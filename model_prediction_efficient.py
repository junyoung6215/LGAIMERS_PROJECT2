import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
import joblib
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier
from sklearn.ensemble import RandomForestClassifier

MODEL_PATH = "open/models"
os.makedirs(MODEL_PATH, exist_ok=True)

def load_and_preprocess_data():
    """
    train.csvì™€ test.csvë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ ìˆ˜í–‰.
    - train.csv: í•™ìŠµ ë°ì´í„°ì™€ íƒ€ê²Ÿ ë¶„ë¦¬ (ë§Œì•½ "ID" ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì œê±°)
    - test.csv: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë° ID ë¶„ë¦¬ (ID ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©)
    - ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê²°ì¸¡ì¹˜ëŠ” "missing"ìœ¼ë¡œ ì±„ìš°ê³  Label Encoding ì ìš©
    """
    print("\n=== ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì‹œì‘ ===")
    try:
        train = pd.read_csv("train.csv")
        test = pd.read_csv("test.csv")
        print("âœ“ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None, None, None, None

    # train ë°ì´í„°ì— 'ID' ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì œê±°í•©ë‹ˆë‹¤.
    if "ID" in train.columns:
        train = train.drop(columns=["ID"])
    
    # í•™ìŠµ ë°ì´í„°ì™€ íƒ€ê²Ÿ ë¶„ë¦¬
    X = train.drop(columns=["ì„ì‹  ì„±ê³µ ì—¬ë¶€"])
    y = train["ì„ì‹  ì„±ê³µ ì—¬ë¶€"]
    
    # test ë°ì´í„°ì—ì„œ 'ID' ì»¬ëŸ¼ì€ ì¶”í›„ ì œì¶œìš©ìœ¼ë¡œ ë¶„ë¦¬
    if "ID" in test.columns:
        test_ids = test["ID"].values
        X_test = test.drop(columns=["ID"])
    else:
        print("â„¹ï¸ test.csvì— 'ID' ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        test_ids = np.arange(len(test))
        X_test = test.copy()

    # ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬: ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° ë° Label Encoding ì ìš©
    from sklearn.preprocessing import LabelEncoder
    cat_features = X.select_dtypes(include=['object']).columns.tolist()
    for col in cat_features:
        X[col] = X[col].fillna("missing")
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col])
    cat_features_test = X_test.select_dtypes(include=['object']).columns.tolist()
    for col in cat_features_test:
        X_test[col] = X_test[col].fillna("missing")
        le = LabelEncoder()
        X_test[col] = le.fit_transform(X_test[col])
    
    print(f"âœ“ í•™ìŠµ ë°ì´í„° shape: {X.shape}")
    print(f"âœ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° shape: {X_test.shape}")
    
    return X, X_test, y, test_ids

def clean_params(params):
    """íŒŒë¼ë¯¸í„°ì—ì„œ ë¶ˆí•„ìš”í•œ í‚¤ ì œê±°"""
    if isinstance(params, dict):
        if "params" in params:
            model_params = params["params"]
        else:
            model_params = params.copy()
        model_params.pop("roc_auc", None)
        model_params.pop("score", None)
        return model_params
    return params

def load_model_params(model_name):
    """ê° ëª¨ë¸ë³„ íŒŒë¼ë¯¸í„° ë¡œë“œ"""
    # ëª¨ë¸ëª…ê³¼ íŒŒì¼ëª… ë§¤í•‘
    file_name_mapping = {
        "xgb": "xgb",
        "lgb": "lgbm",  # lightgbmë„ ì²˜ë¦¬
        "cat": "catboost",  # catboostë¡œ ìˆ˜ì •
        "rf": "rf"
    }
    
    try:
        if model_name == "lgb":
            # LightGBMì€ ë‘ ê°€ì§€ íŒŒì¼ëª… ì‹œë„
            try:
                params = joblib.load('open/best_lgbm_params.pkl')
            except:
                params = joblib.load('open/best_lightgbm_params.pkl')
        else:
            # ë§¤í•‘ëœ íŒŒì¼ëª… ì‚¬ìš©
            mapped_name = file_name_mapping.get(model_name, model_name)
            params = joblib.load(f'open/best_{mapped_name}_params.pkl')
        
        print(f"âœ… {model_name} íŒŒë¼ë¯¸í„° ë¡œë“œ ì„±ê³µ")
        return clean_params(params)
    except Exception as e:
        print(f"âŒ {model_name} íŒŒë¼ë¯¸í„° ë¡œë“œ ì‹¤íŒ¨ (íŒŒì¼: best_{file_name_mapping.get(model_name, model_name)}_params.pkl)")
        print(f"  ì—ëŸ¬ ë©”ì‹œì§€: {str(e)}")
        return None

def print_model_performance_table(scores):
    """ëª¨ë¸ë³„ ì„±ëŠ¥ì„ í…Œì´ë¸” í˜•íƒœë¡œ ì¶œë ¥"""
    print("\n=== ğŸ“Š ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ ===")
    print("-" * 45)
    print(f"{'ëª¨ë¸ëª…'.ljust(15)} {'ê²€ì¦ ROC-AUC'.rjust(15)} {'í…ŒìŠ¤íŠ¸ ROC-AUC'.rjust(15)}")
    print("-" * 45)
    for model_name, score_dict in scores.items():
        val_score = score_dict.get('val_score', 0)
        test_score = score_dict.get('test_score', 0)
        print(f"{model_name.ljust(15)} {f'{val_score:.4f}'.rjust(15)} {f'{test_score:.4f}'.rjust(15)}")
    print("-" * 45)

def train_and_predict(model_class, params, X_train, y_train, X_test, model_name):
    """ê°œë³„ ëª¨ë¸ í•™ìŠµ/ë¡œë“œ ë° ì˜ˆì¸¡"""
    print(f"\n=== {model_name} ëª¨ë¸ ì²˜ë¦¬ ì‹œì‘ ===")
    
    model_path = f"{MODEL_PATH}/{model_name}_model.pkl"
    performance_path = f"{MODEL_PATH}/{model_name}_performance.pkl"
    
    if os.path.exists(model_path):
        print(f"[{model_name}] â„¹ï¸ ì €ì¥ëœ ëª¨ë¸ ë°œê²¬, ë¡œë“œ ì¤‘...")
        try:
            model = joblib.load(model_path)
            if os.path.exists(performance_path):
                performance = joblib.load(performance_path)
                print(f"[{model_name}] ğŸ“ˆ ì €ì¥ëœ ì„±ëŠ¥ ì§€í‘œ:")
                print(f"    - ê²€ì¦ ROC-AUC: {performance.get('val_score', 0):.4f}")
                print(f"    - í…ŒìŠ¤íŠ¸ ROC-AUC: {performance.get('test_score', 0):.4f}")
            return model, performance
        except Exception as e:
            print(f"[{model_name}] âš ï¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            print(f"[{model_name}] ğŸ”„ ìƒˆë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    else:
        print(f"[{model_name}] â„¹ï¸ ì €ì¥ëœ ëª¨ë¸ ì—†ìŒ, ìƒˆë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")
    
    # ëª¨ë¸ í•™ìŠµ
    if model_name == "xgb":
        model = model_class(**params, use_label_encoder=False, eval_metric="auc")
    elif model_name == "cat":
        model = model_class(**params, verbose=False, eval_metric="AUC")
    else:
        model = model_class(**params)
    
    model.fit(X_train, y_train)
    
    # ëª¨ë¸ ì €ì¥
    try:
        joblib.dump(model, model_path)
        print(f"[{model_name}] âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
    except Exception as e:
        print(f"[{model_name}] âš ï¸ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    return model, None

def main():
    print("\nğŸš€ ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    
    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    X, X_test, y, test_ids = load_and_preprocess_data()
    if X is None:
        return
    
    # ê²€ì¦ìš© ë¶„í• 
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    models_config = {
        "xgb": (xgb.XGBClassifier, "xgb"),
        "lgb": (lgb.LGBMClassifier, "lgb"),
        "cat": (CatBoostClassifier, "cat"),
        "rf": (RandomForestClassifier, "rf")
    }
    
    submissions = {}
    scores = {}
    
    for model_key, (model_class, param_key) in models_config.items():
        try:
            params = load_model_params(param_key)
            if params is None:
                print(f"âš ï¸ {model_key} ëª¨ë¸ ìŠ¤í‚µ: íŒŒë¼ë¯¸í„° ë¡œë“œ ì‹¤íŒ¨")
                continue
            
            # ëª¨ë¸ í•™ìŠµ/ë¡œë“œ ë° ì„±ëŠ¥ ì§€í‘œ í™•ì¸
            model, performance = train_and_predict(
                model_class, params, X_train, y_train, X_test, model_key
            )
            
            # ê²€ì¦ ì„¸íŠ¸ ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€
            val_pred = model.predict_proba(X_val)[:, 1]
            val_score = roc_auc_score(y_val)
            
            # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì˜ˆì¸¡
            test_pred = model.predict_proba(X_test)[:, 1]
            
            # ì„±ëŠ¥ ì €ì¥
            model_scores = {
                'val_score': val_score,
                'test_score': 0  # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë ˆì´ë¸”ì´ ì—†ìœ¼ë¯€ë¡œ 0ìœ¼ë¡œ ì„¤ì •
            }
            scores[model_key] = model_scores
            
            # ì„±ëŠ¥ ì§€í‘œ íŒŒì¼ ì €ì¥
            joblib.dump(model_scores, f"{MODEL_PATH}/{model_key}_performance.pkl")
            
            # ì œì¶œ íŒŒì¼ ìƒì„±
            submission = pd.DataFrame({
                "ID": test_ids,
                "probability": test_pred
            })
            output_path = f"submission_{model_key}.csv"
            submission.to_csv(output_path, index=False)
            print(f"âœ… {model_key} ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_path}")
            
            submissions[model_key] = submission
            
        except Exception as e:
            print(f"âŒ {model_key} ëª¨ë¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    # ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸” ì¶œë ¥
    print_model_performance_table(scores)
    
    return submissions, scores

if __name__ == "__main__":
    main()