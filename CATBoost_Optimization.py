print(">> [CATBoost_Optimization] íŒŒì¼ ì‹¤í–‰ ì‹œìž‘")  # í”„ë¡œê·¸ëž¨ ì‹œìž‘ ë¡œê·¸

import pandas as pd
import numpy as np
from catboost import CatBoostClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import roc_auc_score
import optuna
import joblib
import os

# ê°œì„ ëœ update_best_parameters í•¨ìˆ˜ (í‚¤: "roc_auc"ë¡œ ì¼ê´€)
def update_best_parameters(params_path, new_roc, new_params):
    # ê¸°ì¡´ pkl íŒŒì¼ ë¡œë“œ ì—¬ë¶€ í™•ì¸ ë° ë¡œë“œ
    if os.path.exists(params_path):
        old_record = joblib.load(params_path)
        old_roc = old_record.get("roc_auc", 0)
        print(f"[LOG] ê¸°ì¡´ pkl íŒŒì¼ ë¡œë“œ ì„±ê³µ: {old_record}")  # ê¸°ì¡´ ê¸°ë¡ í™•ì¸ ë¡œê·¸
    else:
        old_roc = 0
        print("[LOG] ê¸°ì¡´ pkl íŒŒì¼ì´ ì—†ìŒ. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
    
    print(f"[LOG] ìƒˆë¡œ ì‹œë„ëœ ROC-AUC: {new_roc:.4f}, ê¸°ì¡´ ROC-AUC: {old_roc:.4f}")
    
    # ìƒˆ ìŠ¤ì½”ì–´ê°€ ê¸°ì¡´ ìŠ¤ì½”ì–´ë³´ë‹¤ ë†’ì„ ê²½ìš° ê¸°ë¡ ì—…ë°ì´íŠ¸ 
    if new_roc > old_roc:
        best_record = {"params": new_params, "roc_auc": new_roc}
        joblib.dump(best_record, params_path)
        print(f"[LOG] ðŸ† íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ: ìƒˆ ROC-AUC = {new_roc:.4f}, ì €ìž¥ëœ íŒŒë¼ë¯¸í„°: {new_params}")
    else:
        print(f"[LOG] â„¹ ê¸°ì¡´ íŒŒë¼ë¯¸í„° ìœ ì§€: ê¸°ì¡´ ROC-AUC = {old_roc:.4f} >= ìƒˆ ROC-AUC = {new_roc:.4f}")
    return

# Step 1: ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
print(">> [CATBoost_Optimization] Step 1: ë°ì´í„° ë¡œë“œ ë° ë¶„í•  ì‹œìž‘")
data = pd.read_csv("train.csv")
if "ID" in data.columns:
    data = data.drop(columns=["ID"])
print("  [ë°ì´í„° ë¡œë“œ ì™„ë£Œ] train.csv íŒŒì¼ ë¡œë“œ ì„±ê³µ")
X = data.drop(columns=["ìž„ì‹  ì„±ê³µ ì—¬ë¶€"])
y = data["ìž„ì‹  ì„±ê³µ ì—¬ë¶€"]

# ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
cat_features = X.select_dtypes(include=['object']).columns.tolist()
print("  [ì „ì²˜ë¦¬] ë²”ì£¼í˜• ë³€ìˆ˜ ì„¤ì •:", cat_features)
X[cat_features] = X[cat_features].fillna("missing")

# ë°ì´í„° ë¶„í•  (í•™ìŠµ/í…ŒìŠ¤íŠ¸)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print(f"  [ë¶„í•  ì™„ë£Œ] í•™ìŠµ ë°ì´í„°: {X_train.shape}, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")

# í´ëž˜ìŠ¤ ë¶ˆê· í˜• í™•ì¸
neg_count = (y_train == 0).sum()
pos_count = (y_train == 1).sum()
default_scale_pos_weight = neg_count / pos_count if pos_count > 0 else 1
print(f"  [í´ëž˜ìŠ¤ ë¹„ìœ¨] ìŒì„±: {neg_count}, ì–‘ì„±: {pos_count}, ê¸°ë³¸ scale_pos_weight: {default_scale_pos_weight:.2f}\n")

# Optuna ëª©ì  í•¨ìˆ˜ (í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰)
def objective(trial):
    print(f">> [Optuna] Trial {trial.number} ì‹œìž‘")
    param = {
        "depth": trial.suggest_int("depth", 4, 8),
        "learning_rate": trial.suggest_float("learning_rate", 0.02, 0.2, log=True),
        "iterations": trial.suggest_int("iterations", 200, 800, step=50),
        "l2_leaf_reg": trial.suggest_float("l2_leaf_reg", 1e-2, 5.0, log=True),
        "border_count": trial.suggest_int("border_count", 32, 255),
        "bagging_temperature": trial.suggest_float("bagging_temperature", 0.0, 1.0),
        "random_strength": trial.suggest_float("random_strength", 1e-3, 10.0, log=True),
        "auto_class_weights": "Balanced",
        "verbose": False
    }
    print(f"  [Optuna] Trial {trial.number} ì„¤ì • íŒŒë¼ë¯¸í„°: {param}")
    model = CatBoostClassifier(cat_features=cat_features, **param, eval_metric="AUC")
    model.fit(X_train, y_train)
    print(f"  [Optuna] Trial {trial.number} ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    y_prob = model.predict_proba(X_test)[:, 1]
    auc = roc_auc_score(y_test, y_prob)
    print(f">> [Optuna] Trial {trial.number} ì™„ë£Œ: ROC-AUC = {auc:.4f}\n")
    return auc

def optimize_catboost():
    best_param_file = "open/best_catboost_params.pkl"
    old_score = 0
    if os.path.exists(best_param_file):
        best_old = joblib.load(best_param_file)
        old_score = best_old.get("roc_auc", 0)
        print(f"[LOG] ê¸°ì¡´ CatBoost ìµœì í™” pkl íŒŒì¼ ë¡œë“œë¨: {best_old}")
    else:
        print("[LOG] ê¸°ì¡´ CatBoost pkl íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    study = optuna.create_study(direction="maximize", pruner=optuna.pruners.MedianPruner(n_warmup_steps=20))
    study.optimize(objective, n_trials=50)
    new_score = study.best_value
    print(f"[LOG] ìµœì í™” ì™„ë£Œ: ìƒˆ ROC-AUC = {new_score:.4f}")
    
    if new_score > old_score:
        best_params = study.best_params
        best_params["roc_auc"] = new_score
        joblib.dump(best_params, best_param_file)
        print(f"[LOG] ìƒˆ íŒŒë¼ë¯¸í„° {best_params} ê°€ pkl íŒŒì¼ì— ì €ìž¥ë¨.")
    else:
        print(f"[LOG] ê¸°ì¡´ íŒŒë¼ë¯¸í„° ìœ ì§€: ê¸°ì¡´ ROC-AUC = {old_score:.4f}")
    
    # ê°±ì‹ ëœ íŒŒë¼ë¯¸í„° ì €ìž¥ (ì—…ë°ì´íŠ¸ í•¨ìˆ˜ ì‚¬ìš©)
    update_best_parameters(best_param_file, study.best_value, study.best_params)

# Step 2: Optuna ìµœì í™” ìˆ˜í–‰
print(">> [CATBoost_Optimization] Step 2: Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œìž‘")
study = optuna.create_study(
    direction="maximize",
    pruner=optuna.pruners.MedianPruner(n_warmup_steps=20)
)
study.optimize(objective, n_trials=50)

print(">> [CATBoost_Optimization] ìµœì í™” ì™„ë£Œ")
print("  ìµœì ì˜ ROC-AUC:", study.best_value)
print("  ìµœì ì˜ íŒŒë¼ë¯¸í„°:", study.best_params)

# ìµœì  íŒŒë¼ë¯¸í„° ì €ìž¥ (ì—…ë°ì´íŠ¸ ë‹¨ê³„)
if not os.path.exists('open'):
    os.makedirs('open')
best_params_path = "open/best_catboost_params.pkl"
update_best_parameters(best_params_path, study.best_value, study.best_params)

# Step 3: ìµœì  íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ìž¬í•™ìŠµ
print(">> [CATBoost_Optimization] Step 3: ìµœì  ëª¨ë¸ ìž¬í•™ìŠµ ì‹œìž‘")
best_model = CatBoostClassifier(
    cat_features=cat_features,
    eval_metric="AUC",
    **study.best_params
)
best_model.fit(X_train, y_train)
print("  [ëª¨ë¸ ìž¬í•™ìŠµ ì™„ë£Œ]")

# Step 4: K-Fold ê¸°ë°˜ ì•™ìƒë¸” í‰ê°€ í•¨ìˆ˜
def evaluate_ensemble_roc_kfold(X, y, model_params, cat_features, n_splits=5):
    print(">> [ì•™ìƒë¸” í‰ê°€] K-Fold í‰ê°€ ì‹œìž‘")
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    oof_preds = np.zeros(len(y))
    auc_scores = []
    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):
        print(f"  [Fold {fold + 1}/{n_splits}] í›ˆë ¨ ì‹œìž‘")
        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]
        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]

        # ê° Foldë§ˆë‹¤ ëª¨ë¸ í•™ìŠµ
        model = CatBoostClassifier(
            cat_features=cat_features,
            eval_metric="AUC",
            **model_params
        )
        model.fit(X_train_fold, y_train_fold, verbose=False)
        print(f"  [Fold {fold + 1}] í•™ìŠµ ì™„ë£Œ")
        
        # ì˜ˆì¸¡ ë° ROC-AUC ê³„ì‚°
        y_pred = model.predict_proba(X_val_fold)[:, 1]
        oof_preds[val_idx] = y_pred
        fold_auc = roc_auc_score(y_val_fold, y_pred)
        auc_scores.append(fold_auc)
        print(f"  [Fold {fold + 1}] ROC-AUC: {fold_auc:.4f}")
        
    final_auc = roc_auc_score(y, oof_preds)
    print(f">> [ì•™ìƒë¸” í‰ê°€] ì „ì²´ ROC-AUC: {final_auc:.4f}")
    print(f">> [ì•™ìƒë¸” í‰ê°€] í‰ê·  Fold ROC-AUC: {np.mean(auc_scores):.4f}, í‘œì¤€íŽ¸ì°¨: {np.std(auc_scores):.4f}")
    return final_auc, oof_preds, auc_scores

# Step 5: ì•™ìƒë¸” í‰ê°€ ìˆ˜í–‰ ë° ê²°ê³¼ ë¹„êµ
print(">> [CATBoost_Optimization] Step 5: ì•™ìƒë¸” í‰ê°€ ì§„í–‰")
kfold_auc, oof_predictions, fold_scores = evaluate_ensemble_roc_kfold(
    X, y, study.best_params, cat_features, n_splits=5
)
print("=== ìµœì¢… ì„±ëŠ¥ ë¹„êµ ===")
print(f"  ë‹¨ì¼ ëª¨ë¸ ROC-AUC: {study.best_value:.4f}")
print(f"  K-Fold ì•™ìƒë¸” ROC-AUC: {kfold_auc:.4f}")
print(f"  ì„±ëŠ¥ ì°¨ì´: {(kfold_auc - study.best_value):.4f}")

# Step 6: OOF ì˜ˆì¸¡ê°’ ì €ìž¥
print(">> [CATBoost_Optimization] Step 6: OOF ì˜ˆì¸¡ê°’ ì €ìž¥ ì‹œìž‘")
oof_predictions_df = pd.DataFrame({'true_values': y, 'oof_predictions': oof_predictions})
oof_predictions_df.to_csv('open/catboost_oof_predictions.csv', index=False)
print(">> [CATBoost_Optimization] ëª¨ë“  ìž‘ì—… ì™„ë£Œ")

if __name__ == "__main__":
    optimize_catboost()
