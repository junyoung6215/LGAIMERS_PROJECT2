import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import roc_auc_score
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier
import joblib
import gc
import os

MODEL_PATH = "open/models"
os.makedirs(MODEL_PATH, exist_ok=True)

def load_best_params():
    """ì €ì¥ëœ ìµœì  íŒŒë¼ë¯¸í„° íŒŒì¼ì—ì„œ ê° ëª¨ë¸ì˜ 'params' ë¶€ë¶„ë§Œ ë¶ˆëŸ¬ì˜´"""
    try:
        best_params = {}
        # XGBoost
        xgb_params = joblib.load('open/best_xgb_params.pkl')
        xgb_dict = xgb_params["params"] if isinstance(xgb_params, dict) and "params" in xgb_params else xgb_params
        xgb_dict.pop("roc_auc", None)  # "roc_auc" í‚¤ ì œê±°
        best_params["xgb"] = xgb_dict

        # LightGBM
        try:
            lgb_params = joblib.load('open/best_lgbm_params.pkl')
        except Exception:
            lgb_params = joblib.load('open/best_lightgbm_params.pkl')
        lgb_dict = lgb_params["params"] if isinstance(lgb_params, dict) and "params" in lgb_params else lgb_params
        lgb_dict.pop("roc_auc", None)
        best_params["lgb"] = lgb_dict

        # CatBoost
        cat_params = joblib.load('open/best_catboost_params.pkl')
        cat_dict = cat_params["params"] if isinstance(cat_params, dict) and "params" in cat_params else cat_params
        cat_dict.pop("roc_auc", None)
        best_params["cat"] = cat_dict

        # RandomForest
        rf_params = joblib.load('open/best_rf_params.pkl')
        rf_dict = rf_params["params"] if isinstance(rf_params, dict) and "params" in rf_params else rf_params
        rf_dict.pop("roc_auc", None)
        best_params["rf"] = rf_dict

        print("âœ“ ëª¨ë“  ëª¨ë¸ì˜ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return best_params
    except Exception as e:
        print(f"âŒ íŒŒë¼ë¯¸í„° ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}")
        return None

def load_and_merge_params():
    """ì—¬ëŸ¬ ëª¨ë¸ì˜ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ í•˜ë‚˜ì˜ dictë¡œ ë³‘í•© í›„ ì €ì¥"""
    try:
        params = {
            "xgb": joblib.load('open/best_xgb_params.pkl'),
            "lgb": None,
            "cat": joblib.load('open/best_catboost_params.pkl')
        }
        try:
            lgb_params = joblib.load('open/best_lgbm_params.pkl')
        except Exception:
            lgb_params = joblib.load('open/best_lightgbm_params.pkl')
        params["lgb"] = lgb_params

        # ê° ëª¨ë¸ íŒŒë¼ë¯¸í„°ì—ì„œ ë©”íƒ€ì •ë³´(roc_auc) ì œê±°
        for key in params:
            model_params = params[key]["params"] if isinstance(params[key], dict) and "params" in params[key] else params[key]
            model_params.pop("roc_auc", None)
            params[key] = model_params

        joblib.dump(params, 'open/best_params.pkl')
        print("âœ“ ëª¨ë“  ëª¨ë¸ì˜ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí•˜ê³  ë³‘í•©í–ˆìŠµë‹ˆë‹¤.")
        return params
    except Exception as e:
        print(f"âŒ íŒŒë¼ë¯¸í„° ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}")
        return None

def load_or_train_models(x_train, y_train, best_params, force_retrain=False):
    models = {
        "xgboost": xgb.XGBClassifier(**best_params["xgb"], use_label_encoder=False),
        "lightgbm": lgb.LGBMClassifier(**best_params["lgb"]),
        "catboost": CatBoostClassifier(**best_params["cat"], verbose=False)
    }
    
    for name, model in models.items():
        model_path = f"{MODEL_PATH}/{name}_model.pkl"
        if os.path.exists(model_path) and not force_retrain:
            print(f"{name} ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
            models[name] = joblib.load(model_path)
        else:
            print(f"{name} ëª¨ë¸ í•™ìŠµ ì¤‘...")
            model.fit(x_train, y_train)
            joblib.dump(model, model_path)
            print(f"{name} ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ")
    
    return models

def optimize_blend_ratios_kfold(models, X, y, n_splits=5):
    print("\nğŸ”„ K-Fold ê¸°ë°˜ ë¸”ë Œë”© ê°€ì¤‘ì¹˜ ìµœì í™” ì‹œì‘")
    print(f"  â€¢ ë°ì´í„° í¬ê¸°: {len(X)} ìƒ˜í”Œ")
    print(f"  â€¢ Fold ìˆ˜: {n_splits}")
    print(f"  â€¢ ëª¨ë¸ ê°œìˆ˜: {len(models)} (XGBoost, LightGBM, CatBoost)")
    
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    def objective(trial):
        trial_num = trial.number + 1
        print(f"\nğŸ“Š Trial {trial_num} ì‹œì‘")
        weights = {
            'xgboost': trial.suggest_float('xgboost', 0.0, 1.0),
            'lightgbm': trial.suggest_float('lightgbm', 0.0, 1.0),
            'catboost': trial.suggest_float('catboost', 0.0, 1.0)
        }
        total = sum(weights.values())
        weights = {k: v/total for k, v in weights.items()}
        print("  ğŸ“ˆ í˜„ì¬ ì‹œë„ ì¤‘ì¸ ê°€ì¤‘ì¹˜:")
        for model_name, weight in weights.items():
            print(f"    â€¢ {model_name}: {weight:.4f} ({weight*100:.1f}%)")
        
        trial_oof_preds = np.zeros(len(y))
        fold_scores = []
        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):
            print(f"\n  ğŸ”„ Fold {fold}/{n_splits} ì§„í–‰ ì¤‘")
            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]
            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]
            preds = {}
            for name, model in models.items():
                print(f"    ğŸ”§ {name} ëª¨ë¸ í•™ìŠµ ì¤‘...")
                if name == "xgboost":
                    model.fit(X_train_fold, y_train_fold, verbose=False)
                elif name == "lightgbm":
                    model.fit(X_train_fold, y_train_fold)
                elif name == "catboost":
                    model.fit(X_train_fold, y_train_fold, silent=True)
                preds[name] = model.predict_proba(X_val_fold)[:, 1]
                fold_score = roc_auc_score(y_val_fold, preds[name])
                print(f"      â†³ {name} Fold {fold} ROC-AUC: {fold_score:.4f}")
            fold_blend = sum(weights[name] * pred for name, pred in preds.items())
            trial_oof_preds[val_idx] = fold_blend
            fold_blend_score = roc_auc_score(y_val_fold, fold_blend)
            fold_scores.append(fold_blend_score)
            print(f"    âœ¨ Fold {fold} ë¸”ë Œë”© ROC-AUC: {fold_blend_score:.4f}")
        
        final_auc = roc_auc_score(y, trial_oof_preds)
        print(f"\n  ğŸ“Š Trial {trial_num} ê²°ê³¼:")
        print(f"    â€¢ í‰ê·  Fold ROC-AUC: {np.mean(fold_scores):.4f}")
        print(f"    â€¢ ì „ì²´ ROC-AUC: {final_auc:.4f}")
        print(f"    â€¢ Fold ì ìˆ˜ í¸ì°¨: {np.std(fold_scores):.4f}")
        return final_auc

    print("\nğŸ” Optuna ìµœì í™” ì‹œì‘")
    import optuna
    study = optuna.create_study(direction="maximize")
    study.optimize(objective, n_trials=100)
    
    best_weights = {k: v/sum(study.best_params.values()) for k, v in study.best_params.items()}
    print("\nğŸ† ìµœì¢… ìµœì  ë¸”ë Œë”© ê°€ì¤‘ì¹˜:")
    for model, weight in best_weights.items():
        print(f"  â€¢ {model}: {weight:.4f} ({weight*100:.1f}%)")
    print(f"  â€¢ ìµœì¢… ROC-AUC: {study.best_value:.4f}")
    
    return best_weights

def weighted_blend_predict(models, x_test, weights):
    preds = {}
    for name, model in models.items():
        preds[name] = model.predict_proba(x_test)[:, 1]
        gc.collect()
    final_pred = sum(weights.get(name, 0) * preds[name] for name in models.keys())
    print(f"âœ… ìµœì¢… ì˜ˆì¸¡ê°’ ìƒ˜í”Œ: {final_pred[:10]}")
    return final_pred

def update_best_parameters(file_path, new_score, new_params, param_type="model"):
    """
    íŒŒë¼ë¯¸í„°(ëª¨ë¸ íŒŒë¼ë¯¸í„° ë˜ëŠ” ë¸”ë Œë”© ê°€ì¤‘ì¹˜)ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” í†µí•© í•¨ìˆ˜
    Args:
        file_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
        new_score: ìƒˆë¡œìš´ ROC-AUC ì ìˆ˜
        new_params: ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„° ë˜ëŠ” ê°€ì¤‘ì¹˜
        param_type: "model" ë˜ëŠ” "blend"
    """
    print(f"\n>> [{param_type.upper()}] íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ ê²€í† ")
    if os.path.exists(file_path):
        old_data = joblib.load(file_path)
        old_score = old_data.get("roc_auc", 0)
        print(f"  â€¢ ê¸°ì¡´ ROC-AUC: {old_score:.4f}")
        print(f"  â€¢ ìƒˆë¡œìš´ ROC-AUC: {new_score:.4f}")
        
        if new_score > old_score:
            best_data = {
                "params" if param_type == "model" else "weights": new_params,
                "roc_auc": new_score
            }
            joblib.dump(best_data, file_path)
            print(f"âœ… ì„±ëŠ¥ í–¥ìƒìœ¼ë¡œ ì¸í•œ ì—…ë°ì´íŠ¸ ì™„ë£Œ ({old_score:.4f} â†’ {new_score:.4f})")
            return best_data
        else:
            print(f"â„¹ï¸ ê¸°ì¡´ íŒŒë¼ë¯¸í„° ìœ ì§€ (ìƒˆë¡œìš´ ì„±ëŠ¥ì´ ë” ë‚®ê±°ë‚˜ ê°™ìŒ)")
            return old_data
    else:
        best_data = {
            "params" if param_type == "model" else "weights": new_params,
            "roc_auc": new_score
        }
        joblib.dump(best_data, file_path)
        print(f"âœ¨ ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„° ì €ì¥ ì™„ë£Œ (ROC-AUC: {new_score:.4f})")
        return best_data

def load_blend_weights(weights_path):
    """
    ë¸”ë Œë”© ê°€ì¤‘ì¹˜ë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ ê°€ì¤‘ì¹˜ë¥¼ ë°˜í™˜
    """
    try:
        if os.path.exists(weights_path):
            data = joblib.load(weights_path)
            if isinstance(data, dict):
                # "weights" í‚¤ê°€ ìˆëŠ” ê²½ìš°
                if "weights" in data:
                    return data["weights"], data.get("roc_auc", 0)
                # ì§ì ‘ ê°€ì¤‘ì¹˜ê°€ ì €ì¥ëœ ê²½ìš°
                if all(k in data for k in ["xgboost", "lightgbm", "catboost"]):
                    return data, 0
            print("âš ï¸ ì €ì¥ëœ ê°€ì¤‘ì¹˜ íŒŒì¼ì˜ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ")
        else:
            print("âš ï¸ ì €ì¥ëœ ê°€ì¤‘ì¹˜ íŒŒì¼ì´ ì—†ìŒ")
    except Exception as e:
        print(f"âš ï¸ ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}")
    
    # ê¸°ë³¸ ê°€ì¤‘ì¹˜ ë°˜í™˜
    default_weights = {
        "xgboost": 0.34,
        "lightgbm": 0.33,
        "catboost": 0.33
    }
    print("â„¹ï¸ ê¸°ë³¸ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:", default_weights)
    return default_weights, 0

def save_blend_weights(weights_path, weights, score):
    """
    ë¸”ë Œë”© ê°€ì¤‘ì¹˜ë¥¼ ì§€ì •ëœ í˜•ì‹ìœ¼ë¡œ ì €ì¥
    """
    data = {
        "weights": weights,
        "roc_auc": score
    }
    joblib.dump(data, weights_path)
    print(f"âœ… ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ (ROC-AUC: {score:.4f})")

def run_blending_pipeline(X_train, y_train, X_test, test_ids, force_retrain=False):
    print("\n=== ğŸ“‹ ë¸”ë Œë”© íŒŒì´í”„ë¼ì¸ ì‹œì‘ ===")
    print(f"[CONFIG] force_retrain: {force_retrain}")
    
    # force_retrain ê°’ ì„¤ëª…: Trueì¸ ê²½ìš° ê¸°ì¡´ ì €ì¥ëœ ëª¨ë¸ì„ ë¬´ì‹œí•˜ê³  ì¬í•™ìŠµ, Falseì¸ ê²½ìš° ì €ì¥ëœ ëª¨ë¸ì´ ìˆìœ¼ë©´ ë¡œë“œí•©ë‹ˆë‹¤.
    print(f"[DEBUG] force_retrain ê°’: {force_retrain} (True: ëª¨ë¸ ì¬í•™ìŠµ, False: ê¸°ì¡´ ì €ì¥ ëª¨ë¸ ì‚¬ìš©)")
    
    # ë°ì´í„° ë¶„í• : ì „ì²´ í•™ìŠµ ë°ì´í„°ë¥¼ ë©”ì¸ í•™ìŠµì…‹ê³¼ ê²€ì¦ì…‹ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    X_train_main, X_val, y_train_main, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
    )
    print("[INFO] ë°ì´í„° ë¶„í•  ì™„ë£Œ: í•™ìŠµ ë©”ì¸ì…‹ê³¼ ê²€ì¦ì…‹ êµ¬ì„±")
    
    best_params = load_and_merge_params()
    if best_params is None:
        print("[ERROR] ìµœì  íŒŒë¼ë¯¸í„° ë¡œë“œ ì‹¤íŒ¨. ë¸”ë Œë”© íŒŒì´í”„ë¼ì¸ ì¢…ë£Œ")
        return None, None, None
    
    print("[INFO] ê°œë³„ ëª¨ë¸ í•™ìŠµ/ë¡œë”© ì‹œì‘")
    models = load_or_train_models(X_train_main, y_train_main, best_params, force_retrain)
    print("[INFO] ê°œë³„ ëª¨ë¸ í•™ìŠµ/ë¡œë”© ì™„ë£Œ")
    
    print("\n=== ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì‹œì‘ ===")
    scores = {}
    for name, model in models.items():
        pred = model.predict_proba(X_val)[:, 1]
        score = roc_auc_score(y_val, pred)
        scores[name] = score
        print(f"[í‰ê°€] {name} ëª¨ë¸ ROC-AUC: {score:.4f}")
    
    weights_path = f"{MODEL_PATH}/blend_weights.pkl"
    if not force_retrain:
        best_weights, old_score = load_blend_weights(weights_path)
        if old_score > 0:
            print(f"[INFO] ê¸°ì¡´ ê°€ì¤‘ì¹˜ ë¡œë“œë¨ (ROC-AUC: {old_score:.4f})")
    
    if force_retrain or old_score == 0:
        print("[INFO] ìƒˆë¡œìš´ ë¸”ë Œë”© ê°€ì¤‘ì¹˜ ìµœì í™” ì‹œì‘")
        best_weights = optimize_blend_ratios_kfold(models, X_train, y_train, n_splits=5)
        # ê²€ì¦ ì„¸íŠ¸ì—ì„œì˜ ì„±ëŠ¥ í‰ê°€
        val_pred = weighted_blend_predict(models, X_val, best_weights)
        new_score = roc_auc_score(y_val, val_pred)
        
        # ê¸°ì¡´ ì ìˆ˜ë³´ë‹¤ ë” ì¢‹ì€ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸
        if new_score > old_score:
            save_blend_weights(weights_path, best_weights, new_score)
            print(f"âœ¨ ì„±ëŠ¥ í–¥ìƒ: {old_score:.4f} â†’ {new_score:.4f}")
        else:
            print(f"â„¹ï¸ ê¸°ì¡´ ê°€ì¤‘ì¹˜ ìœ ì§€ (ê¸°ì¡´: {old_score:.4f} >= ìƒˆë¡œìš´: {new_score:.4f})")
    
    print("\n=== ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰ ===")
    final_pred = weighted_blend_predict(models, X_val, best_weights)
    blend_roc_auc = roc_auc_score(y_val, final_pred)
    scores["ensemble_blend"] = blend_roc_auc
    print(f"[í‰ê°€] ì•™ìƒë¸” ë¸”ë Œë”© ëª¨ë¸ ROC-AUC: {blend_roc_auc:.4f}")
    
    print("\n=== í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ìµœì¢… ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ë³€í™˜ ===")
    final_test_pred = weighted_blend_predict(models, X_test, best_weights)
    submission = pd.DataFrame({
        "ID": test_ids,
        "probability": final_test_pred
    })
    
    submission.to_csv("blend_prediction.csv", index=False)
    if os.path.exists("blend_prediction.csv"):
        print(f"[SUCCESS] 'blend_prediction.csv' íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {os.path.abspath('blend_prediction.csv')}")
    else:
        print("[ERROR] 'blend_prediction.csv' íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
        
    print("=== ğŸ“‹ ë¸”ë Œë”© íŒŒì´í”„ë¼ì¸ ì¢…ë£Œ ===")
    return submission, scores, best_weights

def load_and_preprocess_data():
    """
    train.csvì™€ test.csvë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ ìˆ˜í–‰.
    - train.csv: í•™ìŠµ ë°ì´í„°ì™€ íƒ€ê²Ÿ ë¶„ë¦¬ (ë§Œì•½ "ID" ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì œê±°)
    - test.csv: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë° ID ë¶„ë¦¬ (ID ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©)
    - ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê²°ì¸¡ì¹˜ëŠ” "missing"ìœ¼ë¡œ ì±„ìš°ê³  Label Encoding ì ìš©
    """
    print("\n=== ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì‹œì‘ ===")
    try:
        train = pd.read_csv("train.csv")
        test = pd.read_csv("test.csv")
        print("âœ“ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None, None, None, None

    # train ë°ì´í„°ì—ì„œ 'ID' ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì œê±°
    if "ID" in train.columns:
        train = train.drop(columns=["ID"])
    
    # í•™ìŠµ ë°ì´í„°ì™€ íƒ€ê²Ÿ, í…ŒìŠ¤íŠ¸ ë°ì´í„° ë° ID ë¶„ë¦¬
    X = train.drop(columns=["ì„ì‹  ì„±ê³µ ì—¬ë¶€"])
    y = train["ì„ì‹  ì„±ê³µ ì—¬ë¶€"]
    
    if "ID" in test.columns:
        test_ids = test["ID"].values
        X_test = test.drop(columns=["ID"])
    else:
        print("â„¹ï¸ test.csvì— 'ID' ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        test_ids = np.arange(len(test))
        X_test = test.copy()

    # ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬: ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° ë° Label Encoding ì ìš©
    from sklearn.preprocessing import LabelEncoder
    cat_features = X.select_dtypes(include=['object']).columns.tolist()
    for col in cat_features:
        X[col] = X[col].fillna("missing")
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col])
    cat_features_test = X_test.select_dtypes(include=['object']).columns.tolist()
    for col in cat_features_test:
        X_test[col] = X_test[col].fillna("missing")
        le = LabelEncoder()
        X_test[col] = le.fit_transform(X_test[col])
    
    print(f"âœ“ í•™ìŠµ ë°ì´í„° shape: {X.shape}")
    print(f"âœ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° shape: {X_test.shape}")
    
    return X, X_test, y, test_ids

def main():
    from model_prediction_efficient import load_and_preprocess_data
    print("ë¸”ë Œë”© ëª¨ë¸ ì‹¤í–‰")
    print("ì‚¬ìš© ëª¨ë¸: XGBoost(xgb), LightGBM(lgb), CatBoost(cat)")
    X_train, X_test, y_train, test_ids = load_and_preprocess_data()
    
    # force_retrain ì˜µì…˜ ì²˜ë¦¬ ì˜ˆì‹œ
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--force_retrain', action='store_true',
                      help='Force retrain models and reoptimize weights')
    args = parser.parse_args()
    
    submission, scores, weights = run_blending_pipeline(
        X_train, y_train, X_test, test_ids, 
        force_retrain=args.force_retrain
    )
    if submission is not None:
        print("\n=== ìµœì¢… ì„±ëŠ¥ ìš”ì•½ ===")
        print("-" * 40)
        print("ëª¨ë¸ëª…".ljust(15), "ROC-AUC".rjust(10))
        print("-" * 40)
        for model, score in scores.items():
            print(f"{model.ljust(15)} {score:.4f}".rjust(15))
        print("-" * 40)

if __name__ == "__main__":
    main()

print(">> [model_ensemble] íŒŒì¼ ì‹¤í–‰ ì‹œì‘")

import pandas as pd
import numpy as np
import os
import joblib

# Step 1: ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (ì˜ˆì‹œ)
print(">> [ì•™ìƒë¸”] ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ê°’ ë¡œë“œ ì‹œì‘")
lightgbm_preds = pd.read_csv("open/lightgbm_oof_predictions.csv")
catboost_preds = pd.read_csv("open/catboost_oof_predictions.csv")
# ìƒˆë¡œ ì¶”ê°€: xgboost OOF ì˜ˆì¸¡ê°’ ë¡œë“œ (ë¯¸ë¦¬ ìƒì„±í•˜ì—¬ 'open/xgboost_oof_predictions.csv'ì— ì €ì¥)
xgboost_preds = pd.read_csv("open/xgboost_oof_predictions.csv")
print("  [ì•™ìƒë¸”] ì˜ˆì¸¡ê°’ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")

# ìƒˆë¡œ ì¶”ê°€: ì €ì¥ëœ ë¸”ë Œë”© ê°€ì¤‘ì¹˜ ë¡œë“œ (ì—†ìœ¼ë©´ ë‹¨ìˆœ í‰ê·  ì²˜ë¦¬)
weights_path = "open/models/blend_weights.pkl"
if os.path.exists(weights_path):
    blend_weights = joblib.load(weights_path)
    print("âœ“ ë¸”ë Œë”© ê°€ì¤‘ì¹˜ ë¡œë“œë¨:", blend_weights)
else:
    print("âŒ ë¸”ë Œë”© ê°€ì¤‘ì¹˜ íŒŒì¼ ì—†ìŒ, ë‹¨ìˆœ í‰ê·  ì‚¬ìš©")
    blend_weights = {"lightgbm": 0.33, "catboost": 0.33, "xgboost": 0.34}

# Step 2: ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰
print(">> [ì•™ìƒë¸”] ê°€ì¤‘ì¹˜ ì ìš© ì•™ìƒë¸” ìˆ˜í–‰")
ensemble_preds = blend_weights.get("lightgbm", 0) * lightgbm_preds['oof_predictions'] \
                + blend_weights.get("catboost", 0) * catboost_preds['oof_predictions'] \
                + blend_weights.get("xgboost", 0) * xgboost_preds['oof_predictions']
ensemble_df = pd.DataFrame({
    'true_values': lightgbm_preds['true_values'],
    'ensemble_predictions': ensemble_preds
})
print("  [ì•™ìƒë¸”] ìµœì¢… ì•™ìƒë¸” ì™„ë£Œ")

# Step 3: ì•™ìƒë¸” ê²°ê³¼ ì €ì¥
submission = pd.DataFrame({
    "ID": test_ids,              # í…ŒìŠ¤íŠ¸ ID (ì˜ˆ: "TEST_00000", "TEST_00001", ...)
    "probability": ensemble_preds
})
submission.to_csv("open/ensemble_predictions.csv", index=False)
print(f">> [ì•™ìƒë¸”] ì•™ìƒë¸” ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {os.path.abspath('open/ensemble_predictions.csv')}")
print(">> [model_ensemble] íŒŒì¼ ì‹¤í–‰ ì¢…ë£Œ")

