import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.ensemble import StackingClassifier
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier
import joblib
import gc
from sklearn.metrics import roc_auc_score
import optuna
import os

# ëª¨ë¸ ë° ê°€ì¤‘ì¹˜ ì €ì¥ ê²½ë¡œ ì„¤ì •
MODEL_PATH = "open/models"
os.makedirs(MODEL_PATH, exist_ok=True)

def load_best_params():
    """Optunaë¡œ ì°¾ì€ ìµœì  íŒŒë¼ë¯¸í„° ë¡œë“œ"""
    try:
        best_params = {
            "xgb": joblib.load('open/best_xgb_params.pkl'),
            "lgb": joblib.load('open/best_lgbm_params.pkl'),
            "rf": joblib.load('open/best_rf_params.pkl'),
            "cat": joblib.load('open/best_catboost_params.pkl')
        }
        print("ëª¨ë“  ëª¨ë¸ì˜ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return best_params
    except Exception as e:
        print(f"íŒŒë¼ë¯¸í„° ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}")
        return None

def load_and_merge_params():
    """ê° ëª¨ë¸ì˜ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ë¡œë“œí•˜ê³  ë³‘í•©"""
    try:
        # ê° ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° íŒŒì¼ ë¡œë“œ
        params = {
            "xgb": joblib.load('open/best_xgb_params.pkl'),
            "lgb": joblib.load('open/best_lgbm_params.pkl'),
            "cat": joblib.load('open/best_catboost_params.pkl')
        }
        
        # í†µí•© íŒŒë¼ë¯¸í„° íŒŒì¼ ì €ì¥
        joblib.dump(params, 'open/best_params.pkl')
        print("ëª¨ë“  ëª¨ë¸ì˜ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí•˜ê³  ë³‘í•©í–ˆìŠµë‹ˆë‹¤.")
        return params
    except Exception as e:
        print(f"íŒŒë¼ë¯¸í„° ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}")
        return None

def load_or_train_models(x_train, y_train, best_params, force_retrain=False):
    models = {
        "xgboost": xgb.XGBClassifier(**best_params["xgb"], use_label_encoder=False),
        "lightgbm": lgb.LGBMClassifier(**best_params["lgb"]),
        "catboost": CatBoostClassifier(**best_params["cat"], verbose=False)
    }
    
    for name, model in models.items():
        model_path = f"{MODEL_PATH}/{name}_model.pkl"
        
        if os.path.exists(model_path) and not force_retrain:
            print(f"{name} ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
            models[name] = joblib.load(model_path)
        else:
            print(f"{name} ëª¨ë¸ í•™ìŠµ ì¤‘...")
            model.fit(x_train, y_train)
            joblib.dump(model, model_path)
            print(f"{name} ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ")
    
    return models

def optimize_blend_ratios(models, x_val, y_val):
    """Optunaë¥¼ ì‚¬ìš©í•´ ë¸”ë Œë”© ë¹„ìœ¨ ìµœì í™”"""
    def objective(trial):
        # í‚¤ ì´ë¦„ì„ modelsê³¼ ì¼ì¹˜í•˜ë„ë¡ ìˆ˜ì •
        weights = {
            'xgboost': trial.suggest_float('xgboost', 0.0, 1.0),
            'lightgbm': trial.suggest_float('lightgbm', 0.0, 1.0),
            'catboost': trial.suggest_float('catboost', 0.0, 1.0)
        }
        
        total = sum(weights.values())
        weights = {k: v/total for k, v in weights.items()}
        
        preds = {}
        for name, model in models.items():
            preds[name] = model.predict_proba(x_val)[:, 1]
            gc.collect()
        
        final_pred = sum(weights[name] * pred for name, pred in preds.items())
        return roc_auc_score(y_val, final_pred)

    study = optuna.create_study(direction="maximize")
    study.optimize(objective, n_trials=30)
    
    # ìµœì  ê°€ì¤‘ì¹˜ ì €ì¥ ì‹œì—ë„ ë™ì¼í•œ í‚¤ ì´ë¦„ ì‚¬ìš©
    best_weights = {
        'xgboost': study.best_params['xgboost'],
        'lightgbm': study.best_params['lightgbm'],
        'catboost': study.best_params['catboost']
    }
    
    total = sum(best_weights.values())
    best_weights = {k: v/total for k, v in best_weights.items()}
    
    print("\n=== ìµœì  ë¸”ë Œë”© ê°€ì¤‘ì¹˜ ===")
    for model, weight in best_weights.items():
        print(f"{model}: {weight:.4f} ({weight*100:.1f}%)")
    
    return best_weights

def optimize_blend_ratios_kfold(models, X, y, n_splits=5):
    """K-Fold ê¸°ë°˜ ë¸”ë Œë”© ê°€ì¤‘ì¹˜ ìµœì í™”"""
    print("\nğŸ”„ K-Fold ê¸°ë°˜ ë¸”ë Œë”© ê°€ì¤‘ì¹˜ ìµœì í™” ì‹œì‘")
    print(f"  â€¢ ë°ì´í„° í¬ê¸°: {len(X)} ìƒ˜í”Œ")
    print(f"  â€¢ Fold ìˆ˜: {n_splits}")
    print(f"  â€¢ ëª¨ë¸ ê°œìˆ˜: {len(models)} (XGBoost, LightGBM, CatBoost)")
    
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    def objective(trial):
        trial_num = trial.number + 1
        print(f"\nğŸ“Š Trial {trial_num} ì‹œì‘")
        
        weights = {
            'xgboost': trial.suggest_float('xgboost', 0.0, 1.0),
            'lightgbm': trial.suggest_float('lightgbm', 0.0, 1.0),
            'catboost': trial.suggest_float('catboost', 0.0, 1.0)
        }
        
        total = sum(weights.values())
        weights = {k: v/total for k, v in weights.items()}
        
        print("  ğŸ“ˆ í˜„ì¬ ì‹œë„ ì¤‘ì¸ ê°€ì¤‘ì¹˜:")
        for model_name, weight in weights.items():
            print(f"    â€¢ {model_name}: {weight:.4f} ({weight*100:.1f}%)")
        
        # ê° trialë§ˆë‹¤ oof ì˜ˆì¸¡ê°’ ë°°ì—´ ì´ˆê¸°í™”
        trial_oof_preds = np.zeros(len(y))
        fold_scores = []
        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):
            print(f"\n  ğŸ”„ Fold {fold}/{n_splits} ì§„í–‰ ì¤‘")
            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]
            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]
            
            print(f"    â€¢ í•™ìŠµ ë°ì´í„°: {len(X_train_fold)} ìƒ˜í”Œ")
            print(f"    â€¢ ê²€ì¦ ë°ì´í„°: {len(X_val_fold)} ìƒ˜í”Œ")

            preds = {}
            for name, model in models.items():
                print(f"    ğŸ”§ {name} ëª¨ë¸ í•™ìŠµ ì¤‘...")
                
                # ëª¨ë¸ë³„ë¡œ ì ì ˆí•œ fit() íŒŒë¼ë¯¸í„° ì‚¬ìš©
                if name == "xgboost":
                    model.fit(X_train_fold, y_train_fold, verbose=False)
                elif name == "lightgbm":
                    # LightGBMì€ verbose ì¸ìë¥¼ ìƒëµí•˜ì—¬ ê¸°ë³¸ ë¡œê·¸ ì„¤ì • ì‚¬ìš©
                    model.fit(X_train_fold, y_train_fold)
                elif name == "catboost":
                    model.fit(X_train_fold, y_train_fold, silent=True)
                
                preds[name] = model.predict_proba(X_val_fold)[:, 1]
                fold_score = roc_auc_score(y_val_fold, preds[name])
                print(f"      â†³ {name} Fold {fold} ROC-AUC: {fold_score:.4f}")
            
            fold_blend = sum(weights[name] * pred for name, pred in preds.items())
            trial_oof_preds[val_idx] = fold_blend
            
            fold_blend_score = roc_auc_score(y_val_fold, fold_blend)
            fold_scores.append(fold_blend_score)
            print(f"    âœ¨ Fold {fold} ë¸”ë Œë”© ROC-AUC: {fold_blend_score:.4f}")
        
        final_auc = roc_auc_score(y, trial_oof_preds)
        print(f"\n  ğŸ“Š Trial {trial_num} ê²°ê³¼:")
        print(f"    â€¢ í‰ê·  Fold ROC-AUC: {np.mean(fold_scores):.4f}")
        print(f"    â€¢ ì „ì²´ ROC-AUC: {final_auc:.4f}")
        print(f"    â€¢ Fold ì ìˆ˜ í¸ì°¨: {np.std(fold_scores):.4f}")
        
        return final_auc

    # Optunaë¡œ ìµœì  ê°€ì¤‘ì¹˜ ì°¾ê¸°
    print("\nğŸ” Optuna ìµœì í™” ì‹œì‘")
    study = optuna.create_study(direction="maximize")
    study.optimize(objective, n_trials=30)
    
    best_weights = {k: v/sum(study.best_params.values()) for k, v in study.best_params.items()}
    
    print("\nğŸ† ìµœì¢… ìµœì  ë¸”ë Œë”© ê°€ì¤‘ì¹˜:")
    for model, weight in best_weights.items():
        print(f"  â€¢ {model}: {weight:.4f} ({weight*100:.1f}%)")
    print(f"  â€¢ ìµœì¢… ROC-AUC: {study.best_value:.4f}")
    
    return best_weights

def weighted_blend_predict(models, x_test, weights):
    """ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì˜ˆì¸¡"""
    preds = {}
    for name, model in models.items():
        preds[name] = model.predict_proba(x_test)[:, 1]
        gc.collect()
    
    # weights í‚¤ê°€ "w_xgboost" ë˜ëŠ” "xgboost" í˜•ì‹ ë‘˜ ë‹¤ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ë³€ê²½
    final_pred = sum(weights.get(f"w_{name}", weights.get(name, 0)) * pred for name, pred in preds.items())
    print(f"âœ… ìµœì¢… ì˜ˆì¸¡ê°’ ìƒ˜í”Œ: {final_pred[:10]}")  # ì˜ˆì¸¡ê°’ ì¼ë¶€ ì¶œë ¥
    return final_pred

def run_blending_pipeline(X_train, y_train, X_test, test_ids, force_retrain=False):
    """K-Fold ê¸°ë°˜ ë¸”ë Œë”© íŒŒì´í”„ë¼ì¸"""
    print("\n=== ğŸ“‹ ë¸”ë Œë”© íŒŒì´í”„ë¼ì¸ ì‹œì‘ ===")
    
    # ê²€ì¦ ì„¸íŠ¸ ë¶„ë¦¬
    X_train_main, X_val, y_train_main, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
    )
    
    # ëª¨ë¸ íŒŒë¼ë¯¸í„° ë¡œë“œ ë° ë³‘í•©
    best_params = load_and_merge_params()
    if best_params is None:
        return None, None, None
    
    # ëª¨ë¸ ë¡œë“œ ë˜ëŠ” í•™ìŠµ
    models = load_or_train_models(X_train_main, y_train_main, best_params, force_retrain)
    
    # ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    print("\n=== ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ ===")
    scores = {}
    for name, model in models.items():
        pred = model.predict_proba(X_val)[:, 1]
        score = roc_auc_score(y_val, pred)
        scores[name] = score
        print(f"{name} ROC-AUC: {score:.4f}")
    
    # ë¸”ë Œë”© ê°€ì¤‘ì¹˜ ìµœì í™”: í•­ìƒ ìµœì í™”ë¥¼ ì‹¤í–‰í•˜ë„ë¡ ìˆ˜ì •
    weights_path = f"{MODEL_PATH}/blend_weights.pkl"
    best_weights = optimize_blend_ratios_kfold(models, X_train, y_train, n_splits=5)
    joblib.dump(best_weights, weights_path)
    
    # ë¸”ë Œë”© ì˜ˆì¸¡ ë° ROC-AUC ê³„ì‚°
    final_pred = weighted_blend_predict(models, X_val, best_weights)
    blend_roc_auc = roc_auc_score(y_val, final_pred)
    scores["ensemble_blend"] = blend_roc_auc
    
    print(f"\n=== ì•™ìƒë¸” ë¸”ë Œë”© ëª¨ë¸ ROC-AUC: {blend_roc_auc:.4f} ===")
    
    # ìµœì¢… ì˜ˆì¸¡ ë° CSV ì €ì¥
    final_test_pred = weighted_blend_predict(models, X_test, best_weights)
    submission = pd.DataFrame({
        "ID": test_ids,
        "probability": final_test_pred
    })
    
    submission.to_csv("blend_prediction.csv", index=False)
    if os.path.exists("blend_prediction.csv"):
        print("âœ… blend_prediction.csv íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âŒ blend_prediction.csv íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return submission, scores, best_weights

def main():
    from model_prediction_efficient import load_and_preprocess_data
    
    print("ë¸”ë Œë”© ëª¨ë¸ ì‹¤í–‰")
    print("ì‚¬ìš© ëª¨ë¸: XGBoost(xgb), LightGBM(lgb), CatBoost(cat)")
    
    # ë°ì´í„° ë¡œë“œ
    X_train, X_test, y_train, test_ids = load_and_preprocess_data()
    
    # ë¸”ë Œë”© ì‹¤í–‰
    submission, scores, weights = run_blending_pipeline(
        X_train, y_train, X_test, test_ids, force_retrain=False
    )
    
    if submission is not None:
        # ìµœì¢… ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
        print("\n=== ìµœì¢… ì„±ëŠ¥ ìš”ì•½ ===")
        print("-" * 40)
        print("ëª¨ë¸ëª…".ljust(15), "ROC-AUC".rjust(10))
        print("-" * 40)
        for model, score in scores.items():
            print(f"{model.ljust(15)} {score:.4f}".rjust(15))
        print("-" * 40)

if __name__ == "__main__":
    main()
