import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import roc_auc_score
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier
import joblib
import gc
import os

MODEL_PATH = "open/models"
os.makedirs(MODEL_PATH, exist_ok=True)

def load_best_params():
    """ì €ì¥ëœ ìµœì  íŒŒë¼ë¯¸í„° íŒŒì¼ì—ì„œ ê° ëª¨ë¸ì˜ 'params' ë¶€ë¶„ë§Œ ë¶ˆëŸ¬ì˜´"""
    try:
        best_params = {}
        # XGBoost
        xgb_params = joblib.load('open/best_xgb_params.pkl')
        best_params["xgb"] = xgb_params["params"] if isinstance(xgb_params, dict) and "params" in xgb_params else xgb_params

        # LightGBM
        try:
            lgb_params = joblib.load('open/best_lgbm_params.pkl')
        except Exception:
            lgb_params = joblib.load('open/best_lightgbm_params.pkl')
        best_params["lgb"] = lgb_params["params"] if isinstance(lgb_params, dict) and "params" in lgb_params else lgb_params

        # CatBoost
        cat_params = joblib.load('open/best_catboost_params.pkl')
        best_params["cat"] = cat_params["params"] if isinstance(cat_params, dict) and "params" in cat_params else cat_params

        # RandomForest
        rf_params = joblib.load('open/best_rf_params.pkl')
        best_params["rf"] = rf_params["params"] if isinstance(rf_params, dict) and "params" in rf_params else rf_params

        print("âœ“ ëª¨ë“  ëª¨ë¸ì˜ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return best_params
    except Exception as e:
        print(f"âŒ íŒŒë¼ë¯¸í„° ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}")
        return None

def load_and_merge_params():
    """ì—¬ëŸ¬ ëª¨ë¸ì˜ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ í•˜ë‚˜ì˜ dictë¡œ ë³‘í•© í›„ ì €ì¥"""
    try:
        params = {
            "xgb": joblib.load('open/best_xgb_params.pkl'),
            "lgb": None,
            "cat": joblib.load('open/best_catboost_params.pkl')
        }
        try:
            lgb_params = joblib.load('open/best_lgbm_params.pkl')
        except Exception:
            lgb_params = joblib.load('open/best_lightgbm_params.pkl')
        params["lgb"] = lgb_params

        # í‚¤ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ê°’ ì‚¬ìš©, ì—†ìœ¼ë©´ ì›ë³¸ ì‚¬ìš©
        for key in params:
            params[key] = params[key]["params"] if isinstance(params[key], dict) and "params" in params[key] else params[key]

        joblib.dump(params, 'open/best_params.pkl')
        print("âœ“ ëª¨ë“  ëª¨ë¸ì˜ ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí•˜ê³  ë³‘í•©í–ˆìŠµë‹ˆë‹¤.")
        return params
    except Exception as e:
        print(f"âŒ íŒŒë¼ë¯¸í„° ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}")
        return None

def load_or_train_models(x_train, y_train, best_params, force_retrain=False):
    models = {
        "xgboost": xgb.XGBClassifier(**best_params["xgb"], use_label_encoder=False),
        "lightgbm": lgb.LGBMClassifier(**best_params["lgb"]),
        "catboost": CatBoostClassifier(**best_params["cat"], verbose=False)
    }
    
    for name, model in models.items():
        model_path = f"{MODEL_PATH}/{name}_model.pkl"
        if os.path.exists(model_path) and not force_retrain:
            print(f"{name} ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
            models[name] = joblib.load(model_path)
        else:
            print(f"{name} ëª¨ë¸ í•™ìŠµ ì¤‘...")
            model.fit(x_train, y_train)
            joblib.dump(model, model_path)
            print(f"{name} ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ")
    
    return models

def optimize_blend_ratios_kfold(models, X, y, n_splits=5):
    print("\nğŸ”„ K-Fold ê¸°ë°˜ ë¸”ë Œë”© ê°€ì¤‘ì¹˜ ìµœì í™” ì‹œì‘")
    print(f"  â€¢ ë°ì´í„° í¬ê¸°: {len(X)} ìƒ˜í”Œ")
    print(f"  â€¢ Fold ìˆ˜: {n_splits}")
    print(f"  â€¢ ëª¨ë¸ ê°œìˆ˜: {len(models)} (XGBoost, LightGBM, CatBoost)")
    
    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    def objective(trial):
        trial_num = trial.number + 1
        print(f"\nğŸ“Š Trial {trial_num} ì‹œì‘")
        weights = {
            'xgboost': trial.suggest_float('xgboost', 0.0, 1.0),
            'lightgbm': trial.suggest_float('lightgbm', 0.0, 1.0),
            'catboost': trial.suggest_float('catboost', 0.0, 1.0)
        }
        total = sum(weights.values())
        weights = {k: v/total for k, v in weights.items()}
        print("  ğŸ“ˆ í˜„ì¬ ì‹œë„ ì¤‘ì¸ ê°€ì¤‘ì¹˜:")
        for model_name, weight in weights.items():
            print(f"    â€¢ {model_name}: {weight:.4f} ({weight*100:.1f}%)")
        
        trial_oof_preds = np.zeros(len(y))
        fold_scores = []
        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):
            print(f"\n  ğŸ”„ Fold {fold}/{n_splits} ì§„í–‰ ì¤‘")
            X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]
            y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]
            preds = {}
            for name, model in models.items():
                print(f"    ğŸ”§ {name} ëª¨ë¸ í•™ìŠµ ì¤‘...")
                if name == "xgboost":
                    model.fit(X_train_fold, y_train_fold, verbose=False)
                elif name == "lightgbm":
                    model.fit(X_train_fold, y_train_fold)
                elif name == "catboost":
                    model.fit(X_train_fold, y_train_fold, silent=True)
                preds[name] = model.predict_proba(X_val_fold)[:, 1]
                fold_score = roc_auc_score(y_val_fold, preds[name])
                print(f"      â†³ {name} Fold {fold} ROC-AUC: {fold_score:.4f}")
            fold_blend = sum(weights[name] * pred for name, pred in preds.items())
            trial_oof_preds[val_idx] = fold_blend
            fold_blend_score = roc_auc_score(y_val_fold, fold_blend)
            fold_scores.append(fold_blend_score)
            print(f"    âœ¨ Fold {fold} ë¸”ë Œë”© ROC-AUC: {fold_blend_score:.4f}")
        
        final_auc = roc_auc_score(y, trial_oof_preds)
        print(f"\n  ğŸ“Š Trial {trial_num} ê²°ê³¼:")
        print(f"    â€¢ í‰ê·  Fold ROC-AUC: {np.mean(fold_scores):.4f}")
        print(f"    â€¢ ì „ì²´ ROC-AUC: {final_auc:.4f}")
        print(f"    â€¢ Fold ì ìˆ˜ í¸ì°¨: {np.std(fold_scores):.4f}")
        return final_auc

    print("\nğŸ” Optuna ìµœì í™” ì‹œì‘")
    import optuna
    study = optuna.create_study(direction="maximize")
    study.optimize(objective, n_trials=30)
    
    best_weights = {k: v/sum(study.best_params.values()) for k, v in study.best_params.items()}
    print("\nğŸ† ìµœì¢… ìµœì  ë¸”ë Œë”© ê°€ì¤‘ì¹˜:")
    for model, weight in best_weights.items():
        print(f"  â€¢ {model}: {weight:.4f} ({weight*100:.1f}%)")
    print(f"  â€¢ ìµœì¢… ROC-AUC: {study.best_value:.4f}")
    
    return best_weights

def weighted_blend_predict(models, x_test, weights):
    preds = {}
    for name, model in models.items():
        preds[name] = model.predict_proba(x_test)[:, 1]
        gc.collect()
    final_pred = sum(weights.get(name, 0) * preds[name] for name in models.keys())
    print(f"âœ… ìµœì¢… ì˜ˆì¸¡ê°’ ìƒ˜í”Œ: {final_pred[:10]}")
    return final_pred

def run_blending_pipeline(X_train, y_train, X_test, test_ids, force_retrain=False):
    print("\n=== ğŸ“‹ ë¸”ë Œë”© íŒŒì´í”„ë¼ì¸ ì‹œì‘ ===")
    X_train_main, X_val, y_train_main, y_val = train_test_split(
        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
    )
    
    best_params = load_and_merge_params()
    if best_params is None:
        return None, None, None
    
    models = load_or_train_models(X_train_main, y_train_main, best_params, force_retrain)
    
    print("\n=== ê°œë³„ ëª¨ë¸ ì„±ëŠ¥ ===")
    scores = {}
    for name, model in models.items():
        pred = model.predict_proba(X_val)[:, 1]
        score = roc_auc_score(y_val, pred)
        scores[name] = score
        print(f"{name} ROC-AUC: {score:.4f}")
    
    weights_path = f"{MODEL_PATH}/blend_weights.pkl"
    best_weights = optimize_blend_ratios_kfold(models, X_train, y_train, n_splits=5)
    joblib.dump(best_weights, weights_path)
    
    final_pred = weighted_blend_predict(models, X_val, best_weights)
    blend_roc_auc = roc_auc_score(y_val, final_pred)
    scores["ensemble_blend"] = blend_roc_auc
    
    print(f"\n=== ì•™ìƒë¸” ë¸”ë Œë”© ëª¨ë¸ ROC-AUC: {blend_roc_auc:.4f} ===")
    
    final_test_pred = weighted_blend_predict(models, X_test, best_weights)
    submission = pd.DataFrame({
        "ID": test_ids,
        "probability": final_test_pred
    })
    
    submission.to_csv("blend_prediction.csv", index=False)
    if os.path.exists("blend_prediction.csv"):
        print("âœ… blend_prediction.csv íŒŒì¼ì´ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("âŒ blend_prediction.csv íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    return submission, scores, best_weights

def load_and_preprocess_data():
    """
    train.csvì™€ test.csvë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ ìˆ˜í–‰.
    - train.csv: í•™ìŠµ ë°ì´í„°ì™€ íƒ€ê²Ÿ ë¶„ë¦¬ (ë§Œì•½ "ID" ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì œê±°)
    - test.csv: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë° ID ë¶„ë¦¬ (ID ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©)
    - ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ê²°ì¸¡ì¹˜ëŠ” "missing"ìœ¼ë¡œ ì±„ìš°ê³  Label Encoding ì ìš©
    """
    print("\n=== ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì‹œì‘ ===")
    try:
        train = pd.read_csv("train.csv")
        test = pd.read_csv("test.csv")
        print("âœ“ ë°ì´í„° íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None, None, None, None

    # train ë°ì´í„°ì—ì„œ 'ID' ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì œê±°
    if "ID" in train.columns:
        train = train.drop(columns=["ID"])
    
    # í•™ìŠµ ë°ì´í„°ì™€ íƒ€ê²Ÿ, í…ŒìŠ¤íŠ¸ ë°ì´í„° ë° ID ë¶„ë¦¬
    X = train.drop(columns=["ì„ì‹  ì„±ê³µ ì—¬ë¶€"])
    y = train["ì„ì‹  ì„±ê³µ ì—¬ë¶€"]
    
    if "ID" in test.columns:
        test_ids = test["ID"].values
        X_test = test.drop(columns=["ID"])
    else:
        print("â„¹ï¸ test.csvì— 'ID' ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        test_ids = np.arange(len(test))
        X_test = test.copy()

    # ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬: ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° ë° Label Encoding ì ìš©
    from sklearn.preprocessing import LabelEncoder
    cat_features = X.select_dtypes(include=['object']).columns.tolist()
    for col in cat_features:
        X[col] = X[col].fillna("missing")
        le = LabelEncoder()
        X[col] = le.fit_transform(X[col])
    cat_features_test = X_test.select_dtypes(include=['object']).columns.tolist()
    for col in cat_features_test:
        X_test[col] = X_test[col].fillna("missing")
        le = LabelEncoder()
        X_test[col] = le.fit_transform(X_test[col])
    
    print(f"âœ“ í•™ìŠµ ë°ì´í„° shape: {X.shape}")
    print(f"âœ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° shape: {X_test.shape}")
    
    return X, X_test, y, test_ids

def main():
    from model_prediction_efficient import load_and_preprocess_data
    print("ë¸”ë Œë”© ëª¨ë¸ ì‹¤í–‰")
    print("ì‚¬ìš© ëª¨ë¸: XGBoost(xgb), LightGBM(lgb), CatBoost(cat)")
    X_train, X_test, y_train, test_ids = load_and_preprocess_data()
    submission, scores, weights = run_blending_pipeline(
        X_train, y_train, X_test, test_ids, force_retrain=False
    )
    if submission is not None:
        print("\n=== ìµœì¢… ì„±ëŠ¥ ìš”ì•½ ===")
        print("-" * 40)
        print("ëª¨ë¸ëª…".ljust(15), "ROC-AUC".rjust(10))
        print("-" * 40)
        for model, score in scores.items():
            print(f"{model.ljust(15)} {score:.4f}".rjust(15))
        print("-" * 40)

if __name__ == "__main__":
    main()

print(">> [model_ensemble] íŒŒì¼ ì‹¤í–‰ ì‹œì‘")

import pandas as pd
import numpy as np

# Step 1: ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (ì˜ˆì‹œ)
print(">> [ì•™ìƒë¸”] ê°œë³„ ëª¨ë¸ ì˜ˆì¸¡ê°’ ë¡œë“œ ì‹œì‘")
# ì˜ˆì‹œ: ë‘ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ csv íŒŒì¼ ë¡œë“œ
model1_preds = pd.read_csv("open/lightgbm_oof_predictions.csv")
model2_preds = pd.read_csv("open/catboost_oof_predictions.csv")
print("  [ì•™ìƒë¸”] ì˜ˆì¸¡ê°’ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")

# Step 2: ì•™ìƒë¸” (ì˜ˆ: ë‹¨ìˆœ í‰ê· )
print(">> [ì•™ìƒë¸”] ì˜ˆì¸¡ê°’ í‰ê·  ì•™ìƒë¸” ìˆ˜í–‰")
ensemble_preds = (model1_preds['oof_predictions'] + model2_preds['oof_predictions']) / 2
ensemble_df = pd.DataFrame({
    'true_values': model1_preds['true_values'], 
    'ensemble_predictions': ensemble_preds
})
print("  [ì•™ìƒë¸”] í‰ê·  ì•™ìƒë¸” ì™„ë£Œ")

# Step 3: ì•™ìƒë¸” ê²°ê³¼ ì €ì¥
output_path = "open/ensemble_predictions.csv"
ensemble_df.to_csv(output_path, index=False)
print(f">> [ì•™ìƒë¸”] ì•™ìƒë¸” ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")

print(">> [model_ensemble] íŒŒì¼ ì‹¤í–‰ ì¢…ë£Œ")
